---
title: "Practical 2"
output: pdf_document
---

# EXERCISE 1
```{r}
# Load the dataset
titanic <- read.csv("./datasets/titanic.csv", header = TRUE, sep = ",")
```
```{r}
# Remove the row index column
titanic <- subset(titanic, select = -X)
```

```{r}
# Display the first few rows of the dataset
head(titanic)
```

```{r}
# Display the summary statistics of the dataset
summary(titanic)
```

```{r}
# Create a scatterplot matrix of the dataset
plot(titanic)
```

```{r}
# Using str() function we can see the structure of the dataset
str(titanic)
```

Quantitative (Numerical) Variables:

	•	Freq: Represents the frequency (number of people)

Categorical Variables:

	•	X: Row index (treated as categorical, despite being an integer)
	•	Class: Passenger class (e.g., “1st”, “2nd”, “3rd”, “Crew”)
	•	Sex: Gender (e.g., “Male”, “Female”)
	•	Age: Age group (e.g., “Child”, “Adult”)
	•	Survived: Survival status (e.g., “Yes”, “No”)


# EXERCISE 2
```{r}
# Load the dataset
cars <- read.csv("./datasets/cars.csv", header = TRUE, sep = ",")
```

```{r}
# Make a plot of the distance field in terms of the speed field
plot(cars$speed, cars$dist, xlab = "Speed", ylab = "Distance",
     main = "Distance vs. Speed")
```

```{r}
# Create a histogram of the distance field
plot(cars$dist, xlab = "Distance", main = "Histogram of Distance")
```

```{r}
pdf("./documents/exercice2/distance_vs_speed_plot.pdf")
```

```{r}
# Create a scatterplot of the speed field
plot(cars$speed, cars$dist,
     xlab = "Speed",
     ylab = "Distance",
     main = "Distance vs. Speed",
     col = "#805380")
```

```{r}
dev.off()
```

```{r}
# Save the scatterplot to a PDF file
pdf("./documents/exercice2/modified_distance_vs_speed_plot.pdf")
```

```{r}
# Scatterplot of Distance vs Speed with modified title, axis labels, and color
plot(cars$speed, cars$dist,
     xlab = "Speed",
     ylab = "Distance",
     main = "Distance vs Speed",
     col = "blue")
```

```{r}
dev.off()
```

```{r}
# Save the histogram of the distance field to a PDF file
pdf("./documents/exercice2/ex2_histogram_distance.pdf")
```

```{r}
# Histogram of Distance with modified title, axis labels, and color
hist(cars$dist,
     xlab = "Distance",
     main = "Histogram of Distance",
     col = "green",
     col.main = "red")
```

```{r}
dev.off()
```

```{r}
# Save the histogram of the speed field to a PDF file
pdf("./documents/exercice2/ex2_histogram_speed.pdf")
```

```{r}
# Histogram of Speed with modified title, axis labels, and color
hist(cars$speed,
     xlab = "Speed",
     main = "Histogram of Speed",
     col = "orange",
     col.main = "blue")
```

```{r}
dev.off()
```

# EXERCISE 3

```{r}
# Load the dataset
cars <- read.csv("./datasets/cars.csv", header = TRUE, sep = ",")
```

```{r}
# Remove the first column of the cars data frame
cars <- cars[, -1]
```

```{r}
# Construct a new data frame
new_cars <- data.frame(speed = c(21, 34), dist = c(47, 87))
```

```{r}
# Add the constructed data frame to the cars data frame
cars <- rbind(cars, new_cars)
```

```{r}
# Sort the data in the resulting dataset by column speed (ascending)
cars <- cars[order(cars$speed), ]
```

```{r}
# Write the resulting dataset to a CSV file
write.csv(cars, file = "./datasets/cars_sorted.csv", row.names = FALSE)
```

# EXERCISE 4

```{r}
# Load the dataset
airquality <- read.csv("./datasets/airquality.csv", header = TRUE, sep = ",")
```

```{r}
# Display the first two rows of the dataset
print(airquality[1:2, ])
```

```{r}
# How many rows are in the dataset?
nrow(airquality)
```

```{r}
# What is the value of Ozone in the 40th row?
airquality[40, "Ozone"]
```

```{r}
# How many missing values are there in the Ozone column?
sum(is.na(airquality$Ozone))
```

```{r}
# What is the mean of the Ozone column in this dataset? Exclude NA values
airquality <- read.csv("./datasets/airquality.csv", header = TRUE, sep = ",")
ozone_clean <- na.omit(airquality$Ozone)
print(mean(ozone_clean))
```

```{r}
# Extract the rows where the Ozone value is greater than 31
# and Temp value is greater than 90
airquality <- read.csv("./datasets/airquality.csv", header = TRUE, sep = ",")
airquality <- na.omit(airquality)
airquality_subset <- airquality[airquality$Ozone > 31 & airquality$Temp > 90, ]

# What is the mean of Solar.R in this subset?
print(mean(airquality_subset$Solar.R))
```

# EXERCISE 5
```{r}
# Discretize the Ozone column into 5 bins
aux <- cut(airquality$Ozone,
           breaks = 5,
           labels = c("bin1", "bin2", "bin3", "bin4", "bin5"))
# Add NA to the levels
aux <- addNA(aux)
print(aux)
```

```{r}
# Discretize the Solar.R column into 4 bins
aux <- cut(airquality$Solar.R,
           breaks = 4,
           labels = c("bin1", "bin2", "bin3", "bin4"))

# Add NA to the levels
aux <- addNA(aux)
print(aux)
```

```{r}
# Load the dataset
airquality <- read.csv("./datasets/airquality.csv", header = TRUE, sep = ",")

# Create a new column called "cumulative_days"
cumulative_days <- c(0, 31, 61, 92, 123)

# Add the new column to the dataset and adjust the index (May is month 5)
airquality$AbsDay <- airquality$Day + cumulative_days[airquality$Month - 4]

# Display the updated dataset
head(airquality)
```

# EXERCISE 6
```{r}
# Load the dataset
titanic <- read.csv("./datasets/titanic.csv", header = TRUE, sep = ",")
titanic$Class <- as.numeric(factor(titanic$Class))

# Numerize the Class column
print(titanic$Class <- as.numeric(titanic$Class))
```

```{r}
# Load the dataset
titanic <- read.csv("./datasets/titanic.csv", header = TRUE, sep = ",")

# Create a new data frame (titanic2) by expanding rows based on the Freq column
titanic2 <- titanic[rep(seq_len(nrow(titanic)), titanic$Freq), ]
head(titanic2)
```

```{r}
# Load the dataset
titanic <- read.csv("./datasets/titanic.csv", header = TRUE, sep = ",")

# Define the colors for the bar plots
colors <- c("orange", "#9370DB", "blue", "darkgrey")

# Plot distribution of Class in the original dataset with multiple colors
barplot(table(titanic$Class),
        main = "Class Distribution in Original Titanic Data",
        xlab = "Class",
        ylab = "Frequency",
        col = colors)

# Plot distribution of Class in the original dataset
barplot(table(titanic$Class),
        main = "Class Distribution in Original Titanic Data",
        xlab = "Class",
        ylab = "Frequency",
        col = colors)

# Plot distribution of Class in the new dataset (titanic2)
barplot(table(titanic2$Class),
        main = "Class Distribution in Expanded Titanic Data",
        xlab = "Class",
        ylab = "Frequency",
        col = colors)

# Plot distribution of Survival in the original dataset
barplot(table(titanic$Survived),
        main = "Survival Distribution in Original Titanic Data",
        xlab = "Survived",
        ylab = "Frequency",
        col = c("red", "green"))

# Plot distribution of Survival in the new dataset (titanic2)
barplot(table(titanic2$Survived),
        main = "Survival Distribution in Expanded Titanic Data",
        xlab = "Survived",
        ylab = "Frequency",
        col = c("red", "green"))

# Correlation between Class and Survival in the original dataset
# Create a contingency table
class_survived_table <- table(titanic$Class, titanic$Survived)

# Calculate survival rates by class
survival_rates <- prop.table(class_survived_table, margin = 1)

# Print the contingency table and survival rates
print(class_survived_table)
print(survival_rates)

# Visualizing the relationship

# Bar plot of survival by class
barplot(class_survived_table,
        beside = TRUE,
        col = colors,
        legend = rownames(class_survived_table),
        main = "Survival by Class",
        xlab = "Survived",
        ylab = "Number of Passengers")

# Mosaic plot of Class vs Survived
mosaicplot(~ Class + Survived,
           data = titanic,
           col = c("red", "green"),
           main = "Mosaic Plot of Class vs Survived")

# Correlation between Class and Survival in the new dataset (titanic2)

# Create a contingency table for titanic2
class_survived_table2 <- table(titanic2$Class, titanic2$Survived)

# Calculate survival rates by class for titanic2
survival_rates2 <- prop.table(class_survived_table2, margin = 1)

# Print the contingency table and survival rates for titanic2
print(class_survived_table2)
print(survival_rates2)

# Visualizing the relationship in titanic2

# Bar plot of survival by class in titanic2
barplot(class_survived_table2,
        beside = TRUE,
        col = colors,
        legend = rownames(class_survived_table2),
        main = "Survival by Class (Expanded Titanic Data)",
        xlab = "Survived",
        ylab = "Number of Passengers")

# Mosaic plot of Class vs Survived in titanic2
mosaicplot(~ Class + Survived,
           data = titanic2,
           col = c("red", "green"),
           main = "Mosaic Plot of Class vs Survived (Expanded Titanic Data)")
```

# EXERCISE 7

```{r}
# Load the Airquality dataset
airquality <- read.csv("./datasets/airquality.csv", header = TRUE, sep = ",")

# Clean the dataset
airquality <- na.omit(airquality)

# Calculate the correlation matrix
print(correlation_matrix <- cor(airquality))

# High correlation between Ozone and Temp (0.6985414)
# Low correlation between Wind and Temp (-0.4579883)
```

```{r}
# Load the Cars dataset
cars <- read.csv("./datasets/cars.csv", header = TRUE, sep = ",")

# Clean the dataset
cars <- na.omit(cars)

# Calculate the correlation matrix
print(correlation_matrix <- cor(cars))

# High correlation between all variables
```

```{r}
# Perform a simple random sampling of 50 examples.

# Load the Airquality dataset
airquality <- read.csv("./datasets/airquality.csv", header = TRUE, sep = ",")

# Clean the dataset
airquality <- na.omit(airquality)

# Perform simple random sampling
airquality <- airquality[sample(nrow(airquality), 50), ]
head(airquality)
```

```{r}
# Perform a stratified random sampling of 5 examples each month.
library(dplyr)

# Load the Airquality dataset
airquality <- read.csv("./datasets/airquality.csv", header = TRUE, sep = ",")

# Clean the dataset
airquality <- na.omit(airquality)

# Perform stratified random sampling
airquality <- airquality %>%
  group_by(Month) %>%
  sample_n(5)
head(airquality)
```

# EXERCISE 8

```{r}
# Load the dataset
sales <- read.table("./datasets/sales.txt", header = TRUE, sep = "")

# Calculate the total sales per store using Aggregate()
total_sales_per_store <- aggregate(sales_amount ~ store, data = sales, sum)

total_sales_per_store
```

```{r}
# Load the dataset
sales <- read.table("./datasets/sales.txt", header = TRUE, sep = "")

# Find the avg sales amount for each product category
avg_sales_per_category <- aggregate(sales_amount ~ product_category,
                                    data = sales,
                                    mean)

avg_sales_per_category
```

```{r}
pdf("./documents/exercice8/ex8_total_sales_per_store_category_matrix.pdf")
```

```{r}
library(dplyr)
library(gridExtra)

# Load the dataset
sales <- read.table("./datasets/sales.txt", header = TRUE, sep = "")
str(sales)

# Group the data by store and product category, calculate the total sales
total_sales_per_store_category <- sales %>%
  group_by(store, product_category) %>%
  summarise(total_sales = sum(sales_amount), .groups = "drop")

plot(total_sales_per_store_category)
```

```{r}
dev.off()
```

```{r}
pdf("./documents/exercice8/ex8_total_sales_per_store_category_stacked.pdf")
```

```{r}
library(dplyr)
library(ggplot2)

# Load the dataset
sales <- read.table("./datasets/sales.txt", header = TRUE, sep = "")
str(sales)

# Group the data by store and product category, calculate the total sales
total_sales_per_store_category <- sales %>%
  group_by(store, product_category) %>%
  summarise(total_sales = sum(sales_amount), .groups = "drop")

# Create the stacked bar plot
ggplot(total_sales_per_store_category, aes(x = store, y = total_sales, fill = product_category)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = total_sales),
            position = position_stack(vjust = 0.5),
            size = 3) +
  labs(title = "Total Sales per Store and Product Category",
       x = "Store",
       y = "Total Sales Amount") +
  theme_minimal()
```

```{r}
dev.off()
```

# EXERCISE 9

```{r}
library(dplyr)

# Load the datasets
customers <- read.table("./datasets/customers.txt", header = TRUE, sep = "")
orders <- read.table("./datasets/orders.txt", header = TRUE, sep = "")

# Merge the two datasets by customer_id
merged_data <- inner_join(customers, orders, by = "customer_id")

# Count the number of unique customers in the merged dataset
num_unique_customers <- merged_data %>%
  distinct(customer_id) %>%
  n_distinct()

# Print the number of unique customers
print(num_unique_customers)

# Count the number of orders placed by each customer
order_counts <- table(merged_data$customer_id)

# Print the number of orders placed by each customer
print(order_counts)

# Save the merged dataset as a new CSV file called "customer_orders.csv."
write.csv(merged_data, file = "./datasets/customer_orders.csv", row.names = FALSE)
```